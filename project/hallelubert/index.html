<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Source Themes Academia 4.3.1"><meta name=theme-name content="academia-hugo"><meta name=description content="A focused Hebrew RoBERTa project delivering the first large Hebrew model with state-of-the-art benchmark performance; pre-trained on a TPUv4-128 pod and evaluated on private hardware."><link rel=alternate hreflang=en-us href=/project/hallelubert/><meta name=theme-color content="#d9230f"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.6.0/css/all.css integrity=sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lato:400,700|Open+Sans|Roboto+Mono&display=swap"><link rel=stylesheet href=/css/academia.min.b8ed04d2468929ef2d2df9f77d08dc87.css><link rel=manifest href=/site.webmanifest><link rel=icon type=image/png href=/img/icon.png><link rel=apple-touch-icon type=image/png href=/img/icon-192.png><link rel=canonical href=/project/hallelubert/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Raphael Schmitt â€” AI Researcher | Language Models, NLP & Information Retrieval"><meta property="og:url" content="/project/hallelubert/"><meta property="og:title" content="HalleluBERT | Raphael Schmitt â€” AI Researcher | Language Models, NLP & Information Retrieval"><meta property="og:description" content="A focused Hebrew RoBERTa project delivering the first large Hebrew model with state-of-the-art benchmark performance; pre-trained on a TPUv4-128 pod and evaluated on private hardware."><meta property="og:image" content="/project/hallelubert/featured.png"><meta property="twitter:image" content="/project/hallelubert/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2025-10-24T00:00:00+00:00"><meta property="article:modified_time" content="2025-10-24T00:00:00+00:00"><title>HalleluBERT | Raphael Schmitt â€” AI Researcher | Language Models, NLP & Information Retrieval</title></head><body id=top data-spy=scroll data-target=#TableOfContents data-offset=71><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off role=textbox spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id=navbar-main><div class=container><a class=navbar-brand href=/><img src=/img/raphiniert.png alt="Raphael Schmitt â€” AI Researcher | Language Models, NLP & Information Retrieval"></a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar aria-controls=navbar aria-expanded=false aria-label="Toggle navigation"><span><i class="fas fa-bars"></i></span></button><div class="collapse navbar-collapse" id=navbar><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li><li class=nav-item><a class="nav-link js-search" href=#><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></div></nav><article class="article article-project py-5" itemscope itemtype=http://schema.org/Article><div class="container split-header"><div class="row justify-content-center"><div class=col-lg-8><img class="img-fluid w-100" src=/project/hallelubert/featured_hu0641eb27140ede9f745985b2d192c253_1445349_680x500_fill_q90_lanczos_center_3.png itemprop=image alt>
<span class=article-header-caption>HalleluBERT â€“ a large Hebrew RoBERTa model achieving state-of-the-art performance</span></div><div class=col-lg-8><h1 itemprop=name>HalleluBERT</h1><meta content="2025-10-24 00:00:00 +0000 UTC" itemprop=datePublished><meta content="2025-10-24 00:00:00 +0000 UTC" itemprop=dateModified><div class=article-metadata><span class=article-date><time>Oct 24, 2025</time></span><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=/project/hallelubert/&amp;text=HalleluBERT" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=/project/hallelubert/&amp;t=HalleluBERT" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook-f"></i></a></li><li><a href="mailto:?subject=HalleluBERT&amp;body=/project/hallelubert/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=/project/hallelubert/&amp;title=HalleluBERT" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://web.whatsapp.com/send?text=HalleluBERT%20/project/hallelubert/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=/project/hallelubert/&amp;title=HalleluBERT" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></div></div></div></div><div class=article-container><div class=article-style itemprop=articleBody><h2 id=hallelubert--a-compact-contribution-with-a-state-of-the-art-impact>HalleluBERT â€“ A Compact Contribution with a State-of-the-Art Impact</h2><p>HalleluBERT was designed as a focused, compact research contribution, a small paper with a clear goal: to build a strong Hebrew RoBERTa-style model and evaluate how far pre-training and scaling would push performance in a low-resource setting.</p><p>Although modest in scope, the project delivered something remarkable: the first large Hebrew RoBERTa model trained with a modern pre-training setup, achieving state-of-the-art performance across the evaluation benchmarks we designed.</p><p>The workflow followed the pattern established in earlier projects.<br>The pre-training was executed on a TPUv4-128 pod, while the entire downstream evaluation was performed locally on private basement hardware, using the same workstation that powered GeistBERT and parts of ChristBERT. In that sense, HalleluBERT represents the final chapter of a long hardware-driven research arc, the last model trained with this infrastructure setup.</p><p>From a historical perspective, HalleluBERT is not the most complex or emotionally loaded project in the family. But scientifically, it closes a loop: it rounds off the sequence GottBERT â†’ GeistBERT â†’ ChristBERT with a clean, technically sharp contribution that stands on its own.</p><p>The work is publicly available as an arXiv preprint and currently under review for LREC-COLING 2026.</p><hr><h2 id=links--resources>Links & Resources</h2><ul><li><p><strong>Preprint (2025):</strong><br><a href=https://arxiv.org/abs/2510.21372>https://arxiv.org/abs/2510.21372</a></p></li><li><p>ðŸ¤— <strong>HuggingFace Model Hub:</strong><br><a href=https://huggingface.co/HalleluBERT>https://huggingface.co/HalleluBERT</a></p></li></ul></div><div class=article-tags><a class="badge badge-light" href=/tags/nlp/>NLP</a>
<a class="badge badge-light" href=/tags/language-models/>Language Models</a>
<a class="badge badge-light" href=/tags/hebrew/>Hebrew</a>
<a class="badge badge-light" href=/tags/deep-learning/>Deep Learning</a>
<a class="badge badge-light" href=/tags/model-pretraining/>Model Pretraining</a>
<a class="badge badge-light" href=/tags/low-resource-nlp/>Low-Resource NLP</a>
<a class="badge badge-light" href=/tags/open-source/>Open Source</a></div><div class="media author-card" itemscope itemtype=http://schema.org/Person><div class=media-body><h5 class=card-title itemprop=name><a href=/authors/></a></h5><ul class=network-icon aria-hidden=true></ul></div></div></div></div></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin=anonymous></script><script>hljs.initHighlightingOnLoad()</script><script>const search_index_filename="/index.json",i18n={placeholder:"Search...",results:"results found",no_results:"No results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",talk:"Talks"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/academia.min.8d21580ddffa7e5a3f65db85bca47827.js></script><div class=container><footer class=site-footer><div class=container><div class="row align-items-center"><div class="col-md-6 mb-4 mb-md-0"><p class=powered-by><a href=/privacy/>DatenschutzerklÃ¤rung</a>
&#183;
<a href=/terms/>Impressum</a></p><p class=mb-0>Copyright Â© 2025 &#183;
raphiniert.com</p></div><div class=col-md-6><ul class="list-inline network-icon text-right mb-0"></ul></div></div></div></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>